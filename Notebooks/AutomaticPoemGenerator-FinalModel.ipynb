{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2023-04-27T08:35:46.437464Z","iopub.execute_input":"2023-04-27T08:35:46.438646Z","iopub.status.idle":"2023-04-27T08:35:46.544379Z","shell.execute_reply.started":"2023-04-27T08:35:46.438572Z","shell.execute_reply":"2023-04-27T08:35:46.543485Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"/kaggle/input/nature/Nature.csv\n/kaggle/input/nature/Fantasy.csv\n/kaggle/input/fantasy-model/Fantasy_Model.h5\n/kaggle/input/nature-model/Nature_Model.h5\n/kaggle/input/othertopics-model/otherTopics_Model.h5\n/kaggle/input/othertopics/OtherTopics.csv\n/kaggle/input/emotions-model/Emotions_Model.h5\n/kaggle/input/seasons-nlp/Seasons_Model.h5\n/kaggle/input/virtues-model/Virtues_Model.h5\n/kaggle/input/seasons/Seasons.csv\n/kaggle/input/virtues/Virtues.csv\n/kaggle/input/emotions/Emotions.csv\n","output_type":"stream"}]},{"cell_type":"markdown","source":"**Importing Libraries**","metadata":{}},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport nltk\nfrom nltk import pos_tag\nfrom nltk import RegexpParser\nfrom nltk.corpus import wordnet as wn\nimport matplotlib.pyplot as plt\nimport tensorflow.keras.utils as ku\nfrom wordcloud import WordCloud\nfrom tensorflow.keras.preprocessing.sequence import pad_sequences\nfrom tensorflow.keras.layers import Embedding, LSTM, Dense, Dropout, Bidirectional\nfrom tensorflow.keras.preprocessing.text import Tokenizer\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.optimizers import Adam\nfrom tensorflow.keras import regularizers\nfrom keras.models import load_model","metadata":{"execution":{"iopub.status.busy":"2023-04-27T08:35:49.288021Z","iopub.execute_input":"2023-04-27T08:35:49.288486Z","iopub.status.idle":"2023-04-27T08:36:02.249881Z","shell.execute_reply.started":"2023-04-27T08:35:49.288433Z","shell.execute_reply":"2023-04-27T08:36:02.248528Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"markdown","source":"**Generating the Poem Lines**","metadata":{}},{"cell_type":"code","source":"def GenerateLines(ModelPath, DataPath, SplitVal, Seed, max_sequence_len):\n    seed_text = Seed\n    next_words = 6\n    ouptut_text = \"\"\n    \n    data = pd.read_csv(DataPath)\n    \n    text_data = \"\"\n    for index, row in data.iterrows():\n        text_data = text_data + row['text']\n    \n    corpus = text_data.lower().split(\"\\n\")\n    corpus = corpus[::SplitVal]\n    \n    tokenizer = Tokenizer()\n    tokenizer.fit_on_texts(corpus)\n    \n    model = load_model(ModelPath)\n    \n    for _ in range(next_words):\n        token_list = tokenizer.texts_to_sequences([seed_text])[0]\n        token_list = pad_sequences([token_list], maxlen=max_sequence_len-1, padding='pre')\n        predicted = np.argmax(model.predict(token_list, verbose=0), axis=-1)\n        output_word = \"\"\n\n        for word, index in tokenizer.word_index.items():\n            if index == predicted:\n                output_word = word\n                break\n\n        seed_text += \" \" + output_word\n    \n    corpus = []\n    text_data = \"\"\n    \n    return(seed_text)","metadata":{"execution":{"iopub.status.busy":"2023-04-27T08:36:08.663611Z","iopub.execute_input":"2023-04-27T08:36:08.664724Z","iopub.status.idle":"2023-04-27T08:36:08.674268Z","shell.execute_reply.started":"2023-04-27T08:36:08.664670Z","shell.execute_reply":"2023-04-27T08:36:08.673137Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"markdown","source":"**Including Wordnet**","metadata":{}},{"cell_type":"code","source":"!unzip /usr/share/nltk_data/corpora/wordnet.zip -d /usr/share/nltk_data/corpora/","metadata":{"execution":{"iopub.status.busy":"2023-04-27T08:36:13.202546Z","iopub.execute_input":"2023-04-27T08:36:13.202948Z","iopub.status.idle":"2023-04-27T08:36:14.702629Z","shell.execute_reply.started":"2023-04-27T08:36:13.202912Z","shell.execute_reply":"2023-04-27T08:36:14.701445Z"},"trusted":true},"execution_count":4,"outputs":[{"name":"stdout","text":"Archive:  /usr/share/nltk_data/corpora/wordnet.zip\n   creating: /usr/share/nltk_data/corpora/wordnet/\n  inflating: /usr/share/nltk_data/corpora/wordnet/lexnames  \n  inflating: /usr/share/nltk_data/corpora/wordnet/data.verb  \n  inflating: /usr/share/nltk_data/corpora/wordnet/index.adv  \n  inflating: /usr/share/nltk_data/corpora/wordnet/adv.exc  \n  inflating: /usr/share/nltk_data/corpora/wordnet/index.verb  \n  inflating: /usr/share/nltk_data/corpora/wordnet/cntlist.rev  \n  inflating: /usr/share/nltk_data/corpora/wordnet/data.adj  \n  inflating: /usr/share/nltk_data/corpora/wordnet/index.adj  \n  inflating: /usr/share/nltk_data/corpora/wordnet/LICENSE  \n  inflating: /usr/share/nltk_data/corpora/wordnet/citation.bib  \n  inflating: /usr/share/nltk_data/corpora/wordnet/noun.exc  \n  inflating: /usr/share/nltk_data/corpora/wordnet/verb.exc  \n  inflating: /usr/share/nltk_data/corpora/wordnet/README  \n  inflating: /usr/share/nltk_data/corpora/wordnet/index.sense  \n  inflating: /usr/share/nltk_data/corpora/wordnet/data.noun  \n  inflating: /usr/share/nltk_data/corpora/wordnet/data.adv  \n  inflating: /usr/share/nltk_data/corpora/wordnet/index.noun  \n  inflating: /usr/share/nltk_data/corpora/wordnet/adj.exc  \n","output_type":"stream"}]},{"cell_type":"code","source":"wn.synsets(\"happy\")[0].also_sees() ","metadata":{"execution":{"iopub.status.busy":"2023-04-27T05:06:23.943459Z","iopub.execute_input":"2023-04-27T05:06:23.943894Z","iopub.status.idle":"2023-04-27T05:06:26.081618Z","shell.execute_reply.started":"2023-04-27T05:06:23.943853Z","shell.execute_reply":"2023-04-27T05:06:26.080431Z"},"trusted":true},"execution_count":5,"outputs":[{"execution_count":5,"output_type":"execute_result","data":{"text/plain":"[Synset('cheerful.a.01'),\n Synset('contented.a.01'),\n Synset('elated.a.01'),\n Synset('euphoric.a.01'),\n Synset('felicitous.a.01'),\n Synset('glad.a.01'),\n Synset('joyful.a.01'),\n Synset('joyous.a.01')]"},"metadata":{}}]},{"cell_type":"markdown","source":"**Obtaining the Most SImilar Category**","metadata":{}},{"cell_type":"code","source":"CATEGORIES = {\n    'emotions': [\n        'sorrow',\n        'greed',\n        'fear',\n        'laughter',\n        'love',\n        'hate',\n        'happy',\n        'sympathy',\n        'depression',\n        'hope',\n        'anger'\n    ], \n    'virtues': [\n        'respect',\n        'truth',\n        'justice',\n        'peace',\n        'freedom',\n        'courage',\n        'innocence',\n        'beauty',\n        'lonely', \n        'trust'\n    ],\n    'nature': [\n        'butterfly',\n        'snake',\n        'rose',\n        'moon',\n        'sun',\n        'sky',\n        'star',\n        'rain',\n        'rainbow',\n        'green',\n        'nature',\n        'animal',\n        'fire', \n        'water'\n    ], \n    'fantasy': [\n        'angel',\n        'hero', \n        'heaven', \n        'god',\n        'dream',\n        'believe', \n        'faith', \n        'time',\n        'dark',\n        'destiny'\n    ],\n    'seasons': [\n      'january', \n      'june', \n      'june',\n      'christmas',\n       'spring',\n       'winter',\n       'summer',\n      'weather',\n    ], \n    'other': [\n        'sometimes',  \n        'future',  \n        'mirror',    \n        'remember', \n        'today', \n        'power', \n        'together',  \n        'red',  \n        'success', \n        'crazy', \n        'memory', \n        'money',   \n        'food', \n        'car', \n        'night', \n    ]\n}\n\ndef getCategory(NounWord):\n    maximum = 0\n    Category = \"\"\n    sum1 = 0\n    if(len(wn.synsets(NounWord, 'n')) > 0):\n        cat = wn.synsets(NounWord, 'n')[0]\n        for j in ['emotions', 'virtues', 'nature', 'fantasy', 'seasons', 'other']:\n            sum1 = 0\n            for i in CATEGORIES[j]:\n                if(len(wn.synsets(i, 'n')) > 0):\n                    x = cat.wup_similarity(wn.synsets(i, 'n')[0])\n                    #print(i, x)\n                    sum1 = sum1 + x\n            if(sum1 > maximum):\n                maximum = sum1\n                Category = j\n    return(Category, sum1)\n#argmax Ej Ei similarity(keyword, j[i])","metadata":{"execution":{"iopub.status.busy":"2023-04-27T08:36:18.294432Z","iopub.execute_input":"2023-04-27T08:36:18.294869Z","iopub.status.idle":"2023-04-27T08:36:18.310376Z","shell.execute_reply.started":"2023-04-27T08:36:18.294827Z","shell.execute_reply":"2023-04-27T08:36:18.308696Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"markdown","source":"**Chunking and Obtaining Key Words**","metadata":{}},{"cell_type":"code","source":"def ChunkingSentence(Sentence):\n    text = Sentence.split()\n    #POS Tags\n    POS_tag = pos_tag(text)\n    print(POS_tag)\n    NounTags = []\n    for i in POS_tag:\n        if i[1].startswith(\"NN\"):\n            temp = i[0]\n            NounTags.append(temp)\n        elif i[1].startswith(\"VB\"):\n            temp = i[0]\n            NounTags.append(temp)\n    return(NounTags)","metadata":{"execution":{"iopub.status.busy":"2023-04-27T08:36:20.997341Z","iopub.execute_input":"2023-04-27T08:36:20.998288Z","iopub.status.idle":"2023-04-27T08:36:21.004552Z","shell.execute_reply.started":"2023-04-27T08:36:20.998247Z","shell.execute_reply":"2023-04-27T08:36:21.003314Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"markdown","source":"**Input Sentence for Poem**","metadata":{}},{"cell_type":"code","source":"Query = input(\"Enter the kind of poem you want: \")\nKeyWords = ChunkingSentence(Query)","metadata":{"execution":{"iopub.status.busy":"2023-04-27T08:41:03.949956Z","iopub.execute_input":"2023-04-27T08:41:03.950447Z","iopub.status.idle":"2023-04-27T08:41:12.274404Z","shell.execute_reply.started":"2023-04-27T08:41:03.950407Z","shell.execute_reply":"2023-04-27T08:41:12.272953Z"},"trusted":true},"execution_count":24,"outputs":[{"output_type":"stream","name":"stdin","text":"Enter the kind of poem you want:  about a boy who likes girls\n"},{"name":"stdout","text":"[('about', 'IN'), ('a', 'DT'), ('boy', 'NN'), ('who', 'WP'), ('likes', 'VBZ'), ('girls', 'NNS')]\n","output_type":"stream"}]},{"cell_type":"code","source":"D = dict()\nfor word in KeyWords:\n    Cat, Sum1 = getCategory(word)\n    if(Cat in D):\n        D[Cat] = D[Cat] + Sum1\n    else:\n        D[Cat] = Sum1\nprint(D)\n\nKeymax = max(zip(D.values(), D.keys()))[1]\nprint(Keymax)","metadata":{"execution":{"iopub.status.busy":"2023-04-27T08:41:14.188893Z","iopub.execute_input":"2023-04-27T08:41:14.189312Z","iopub.status.idle":"2023-04-27T08:41:14.251781Z","shell.execute_reply.started":"2023-04-27T08:41:14.189273Z","shell.execute_reply":"2023-04-27T08:41:14.250491Z"},"trusted":true},"execution_count":25,"outputs":[{"name":"stdout","text":"{'nature': 6.0429529534792685, 'fantasy': 2.899030664897538}\nnature\n","output_type":"stream"}]},{"cell_type":"markdown","source":"**Obtaining the Seed Words**","metadata":{}},{"cell_type":"code","source":"for i in KeyWords:\n    #print(wn.synsets(\"girl\")[0].also_sees()) \n    '''for syn in wn.synsets(i):\n        print(syn.hypernyms())'''\n    print(wn.synsets(i))","metadata":{"execution":{"iopub.status.busy":"2023-04-25T02:39:26.929484Z","iopub.execute_input":"2023-04-25T02:39:26.929872Z","iopub.status.idle":"2023-04-25T02:39:26.936192Z","shell.execute_reply.started":"2023-04-25T02:39:26.929834Z","shell.execute_reply":"2023-04-25T02:39:26.934917Z"},"trusted":true},"execution_count":10,"outputs":[{"name":"stdout","text":"[Synset('friend.n.01'), Synset('ally.n.02'), Synset('acquaintance.n.03'), Synset('supporter.n.01'), Synset('friend.n.05')]\n[Synset('internet.n.01')]\n","output_type":"stream"}]},{"cell_type":"code","source":"Seeds = []\nfor i in KeyWords:\n    #print(wn.synsets(\"girl\")[0].also_sees()) \n    for syn in wn.synsets(i):\n        for lemma in syn.lemmas():\n            Seeds.append(lemma.name())\n\nCleanSeeds = []\nfor i in Seeds:\n    x = i.replace(\"_\", \" \")\n    CleanSeeds.append(x)\nSeeds = []\nprint(set(CleanSeeds))","metadata":{"execution":{"iopub.status.busy":"2023-04-27T08:41:18.979287Z","iopub.execute_input":"2023-04-27T08:41:18.980610Z","iopub.status.idle":"2023-04-27T08:41:18.988467Z","shell.execute_reply.started":"2023-04-27T08:41:18.980561Z","shell.execute_reply":"2023-04-27T08:41:18.987081Z"},"trusted":true},"execution_count":26,"outputs":[{"name":"stdout","text":"{'fille', 'young lady', 'wish', 'the like', 'male child', 'son', 'lady friend', 'the likes of', 'young woman', 'female child', 'like', 'boy', 'care', 'girlfriend', 'ilk', 'missy', 'daughter', 'miss', 'girl', 'little girl'}\n","output_type":"stream"}]},{"cell_type":"code","source":"import gensim.downloader\nprint(list(gensim.downloader.info()['models'].keys()))\n\n# Download the \"glove-twitter-25\" embeddings\nglove_vectors = gensim.downloader.load('glove-twitter-25')\n\nfor i in KeyWords:\n    print(glove_vectors.most_similar(i))","metadata":{"execution":{"iopub.status.busy":"2023-04-25T02:39:26.950740Z","iopub.execute_input":"2023-04-25T02:39:26.951522Z","iopub.status.idle":"2023-04-25T02:39:44.132375Z","shell.execute_reply.started":"2023-04-25T02:39:26.951446Z","shell.execute_reply":"2023-04-25T02:39:44.130797Z"},"trusted":true},"execution_count":12,"outputs":[{"name":"stdout","text":"['fasttext-wiki-news-subwords-300', 'conceptnet-numberbatch-17-06-300', 'word2vec-ruscorpora-300', 'word2vec-google-news-300', 'glove-wiki-gigaword-50', 'glove-wiki-gigaword-100', 'glove-wiki-gigaword-200', 'glove-wiki-gigaword-300', 'glove-twitter-25', 'glove-twitter-50', 'glove-twitter-100', 'glove-twitter-200', '__testing_word2vec-matrix-synopsis']\n[==================================================] 100.0% 104.8/104.8MB downloaded\n","output_type":"stream"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m/tmp/ipykernel_27/2664822434.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# Download the \"glove-twitter-25\" embeddings\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mglove_vectors\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgensim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdownloader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'glove-twitter-25'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mKeyWords\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/gensim/downloader.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(name, return_path)\u001b[0m\n\u001b[1;32m    501\u001b[0m         \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minsert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mBASE_DIR\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    502\u001b[0m         \u001b[0mmodule\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m__import__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 503\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    504\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    505\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m~/gensim-data/glove-twitter-25/__init__.py\u001b[0m in \u001b[0;36mload_data\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mload_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0mpath\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbase_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'glove-twitter-25'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'glove-twitter-25.gz'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m     \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mKeyedVectors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_word2vec_format\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/gensim/models/keyedvectors.py\u001b[0m in \u001b[0;36mload_word2vec_format\u001b[0;34m(cls, fname, fvocab, binary, encoding, unicode_errors, limit, datatype, no_header)\u001b[0m\n\u001b[1;32m   1723\u001b[0m         return _load_word2vec_format(\n\u001b[1;32m   1724\u001b[0m             \u001b[0mcls\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfvocab\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfvocab\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbinary\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbinary\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mencoding\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0municode_errors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0municode_errors\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1725\u001b[0;31m             \u001b[0mlimit\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlimit\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdatatype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdatatype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mno_header\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mno_header\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1726\u001b[0m         )\n\u001b[1;32m   1727\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/gensim/models/keyedvectors.py\u001b[0m in \u001b[0;36m_load_word2vec_format\u001b[0;34m(cls, fname, fvocab, binary, encoding, unicode_errors, limit, datatype, no_header, binary_chunk_size)\u001b[0m\n\u001b[1;32m   2071\u001b[0m             )\n\u001b[1;32m   2072\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2073\u001b[0;31m             \u001b[0m_word2vec_read_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfin\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcounts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvocab_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvector_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdatatype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0municode_errors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2074\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mkv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvectors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2075\u001b[0m         logger.info(\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/gensim/models/keyedvectors.py\u001b[0m in \u001b[0;36m_word2vec_read_text\u001b[0;34m(fin, kv, counts, vocab_size, vector_size, datatype, unicode_errors, encoding)\u001b[0m\n\u001b[1;32m   1976\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mline\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34mb''\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1977\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mEOFError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"unexpected end of input; is count incorrect or file otherwise damaged?\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1978\u001b[0;31m         \u001b[0mword\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweights\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_word2vec_line_to_vector\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mline\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdatatype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0municode_errors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1979\u001b[0m         \u001b[0m_add_word_to_kv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcounts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mword\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweights\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvocab_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1980\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/gensim/models/keyedvectors.py\u001b[0m in \u001b[0;36m_word2vec_line_to_vector\u001b[0;34m(line, datatype, unicode_errors, encoding)\u001b[0m\n\u001b[1;32m   1982\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_word2vec_line_to_vector\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mline\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdatatype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0municode_errors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1983\u001b[0m     \u001b[0mparts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_unicode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mline\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrstrip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mencoding\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0municode_errors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\" \"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1984\u001b[0;31m     \u001b[0mword\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweights\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparts\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mdatatype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mparts\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1985\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mword\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweights\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1986\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/gensim/models/keyedvectors.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m   1982\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_word2vec_line_to_vector\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mline\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdatatype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0municode_errors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1983\u001b[0m     \u001b[0mparts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_unicode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mline\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrstrip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mencoding\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0municode_errors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\" \"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1984\u001b[0;31m     \u001b[0mword\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweights\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparts\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mdatatype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mparts\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1985\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mword\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweights\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1986\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "],"ename":"KeyboardInterrupt","evalue":"","output_type":"error"}]},{"cell_type":"markdown","source":"**Actually choosing 4 Seed Words**","metadata":{}},{"cell_type":"code","source":"# importing random module\nimport random\n\n# initializing the value of n\nn = 4\n \n# printing n elements from list\nRandSeeds = random.sample(CleanSeeds, n)\nprint(RandSeeds)","metadata":{"execution":{"iopub.status.busy":"2023-04-27T08:41:28.569519Z","iopub.execute_input":"2023-04-27T08:41:28.570663Z","iopub.status.idle":"2023-04-27T08:41:28.577466Z","shell.execute_reply.started":"2023-04-27T08:41:28.570611Z","shell.execute_reply":"2023-04-27T08:41:28.576169Z"},"trusted":true},"execution_count":30,"outputs":[{"name":"stdout","text":"['boy', 'female child', 'like', 'wish']\n","output_type":"stream"}]},{"cell_type":"markdown","source":"**Calling the Generate Line function with seed words**","metadata":{}},{"cell_type":"code","source":"def MakePoem(ModelPath, DataPath, SplitVal,EmbedLen):\n    for i in RandSeeds:\n        Output = \"\"\n        Output = GenerateLines(ModelPath, DataPath, SplitVal, i, EmbedLen)\n        print(Output)","metadata":{"execution":{"iopub.status.busy":"2023-04-27T08:37:57.079438Z","iopub.execute_input":"2023-04-27T08:37:57.079907Z","iopub.status.idle":"2023-04-27T08:37:57.087266Z","shell.execute_reply.started":"2023-04-27T08:37:57.079864Z","shell.execute_reply":"2023-04-27T08:37:57.085775Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"code","source":"ModelPath = \"/kaggle/input/emotions-model/Emotions_Model.h5\"\nDataPath = \"/kaggle/input/emotions/Emotions.csv\"\nif(Keymax == 'emotions'):\n    MakePoem(ModelPath, DataPath, 4, 235)\nelif(Keymax == 'fantasy'):\n    ModelPath = \"/kaggle/input/fantasy-model/Fantasy_Model.h5\"\n    DataPath = \"/kaggle/input/nature/Fantasy.csv\"\n    MakePoem(ModelPath, DataPath, 5, 445)\nelif(Keymax == 'nature'):\n    ModelPath = \"/kaggle/input/nature-model/Nature_Model.h5\"\n    DataPath = \"/kaggle/input/nature/Nature.csv\"\n    MakePoem(ModelPath, DataPath, 7, 263)\nelif(Keymax == 'seasons'):\n    ModelPath = \"/kaggle/input/seasons-nlp/Seasons_Model.h5\"\n    DataPath = \"/kaggle/input/seasons/Seasons.csv\"\n    MakePoem(ModelPath, DataPath, 5, 255)\nelif(Keymax == 'virtues'):\n    ModelPath = \"/kaggle/input/virtues-model/Virtues_Model.h5\"\n    DataPath = \"/kaggle/input/virtues/Virtues.csv\"\n    MakePoem(ModelPath, DataPath, 3, 117)\nelif(Keymax == 'other'):\n    ModelPath = \"/kaggle/input/othertopics-model/otherTopics_Model.h5\"\n    DataPath = \"/kaggle/input/othertopics/OtherTopics.csv\"\n    MakePoem(ModelPath, DataPath, 9, 2113)","metadata":{"execution":{"iopub.status.busy":"2023-04-27T08:41:32.739062Z","iopub.execute_input":"2023-04-27T08:41:32.739467Z","iopub.status.idle":"2023-04-27T08:41:59.664939Z","shell.execute_reply.started":"2023-04-27T08:41:32.739430Z","shell.execute_reply":"2023-04-27T08:41:59.662726Z"},"trusted":true},"execution_count":31,"outputs":[{"name":"stdout","text":"boy tributaries flimsily hour bound us hugs\nfemale child below the sea rief charmer come\nlike the moon is on your fingers\nwish the river is dotted in cries\n","output_type":"stream"}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}